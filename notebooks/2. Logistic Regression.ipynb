{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b82bbf0-1ca9-49e4-9a1f-907fab37a86f",
   "metadata": {},
   "source": [
    "# Logistic Regression Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ff692a-5c89-476d-a8c6-e267a5a79970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1adc69-cd96-41f7-a612-e8fc7a2e5121",
   "metadata": {},
   "source": [
    "Using the [Heart Attack Analysis & Prediction Dataset](https://www.kaggle.com/rashikrahmanpritom/heart-attack-analysis-prediction-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7ecf83-3a63-46b3-9011-bb3b09469045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp      trtbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg    thalachh        exng     oldpeak         slp         caa  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "            thall      output  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/heart.csv\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f27910-ed55-4828-9219-0a444c364b1d",
   "metadata": {},
   "source": [
    "Let's see the split of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c2a20a2-281b-4cef-8f7d-d374a6058b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17586ac-b208-4869-a915-7e1aaa38bc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    138\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['output'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b911e8e4-821f-4467-a58a-f69676222a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train_x, train_y = train[df.columns.difference([\"output\"])], train[\"output\"]\n",
    "test_x, test_y = test[df.columns.difference([\"output\"])], test[\"output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b125d4bf-69c7-4574-84c7-7649eff5e214",
   "metadata": {},
   "source": [
    "## Basic Logistic Regression, with no added parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e63f0ff2-2357-4c66-9d16-af62bdba5e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watemerald/.pyenv/versions/3.9.2/envs/ml_exploration/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5268c6ae-c6a5-4ae8-bf55-57f3b3c240aa",
   "metadata": {},
   "source": [
    "So, Logistic Regression with the default max number of iterations (100) does not converge. Let's see if increasing it has an effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3317bbc2-65a8-48f3-907d-faf7aeb12955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "logistic_regression.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff03e21-dfe7-446d-bb61-2d46924d6a73",
   "metadata": {},
   "source": [
    "So, it converges with a new max number of iterations. Let's quantify it's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1132fe0-489f-441f-83ce-762457e1c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def print_metrics(model, test_x, test_y):\n",
    "    test_pred = model.predict(test_x) \n",
    "\n",
    "    print(f\"Accuracy: {metrics.accuracy_score(test_y, test_pred)}\")\n",
    "    print(f\"F1: {metrics.f1_score(test_y, test_pred)}\")\n",
    "    print(f\"Precision: {metrics.precision_score(test_y, test_pred)}\")\n",
    "    print(f\"Recall: {metrics.recall_score(test_y, test_pred)}\")\n",
    "    print(f\"AUC: {metrics.roc_auc_score(test_y, test_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ebdd431-1ed5-4f11-837c-e44d43f6a057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8360655737704918\n",
      "F1: 0.8571428571428571\n",
      "Precision: 0.8108108108108109\n",
      "Recall: 0.9090909090909091\n",
      "AUC: 0.8295454545454546\n"
     ]
    }
   ],
   "source": [
    "print_metrics(logistic_regression, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dedda5-ec1e-4a4f-be6a-5df3602f68c8",
   "metadata": {},
   "source": [
    "So the model already performs ok. Let's see if it can be improved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3c6a75-cf42-4f9b-8453-b932b3c95455",
   "metadata": {},
   "source": [
    "## Tuning Logistic Regression\n",
    "\n",
    "LogisticRegression by default uses an *l2* penalty. How do other penalty types affect it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61872fea-a52a-4c2a-ac27-97affccf9424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8524590163934426\n",
      "F1: 0.8732394366197183\n",
      "Precision: 0.8157894736842105\n",
      "Recall: 0.9393939393939394\n",
      "AUC: 0.8446969696969697\n"
     ]
    }
   ],
   "source": [
    "l1_regression = LogisticRegression(max_iter=10000, penalty=\"l1\", solver=\"saga\")\n",
    "l1_regression.fit(train_x, train_y)\n",
    "\n",
    "print_metrics(l1_regression, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7d03a-8571-4a85-93d7-18f14eceb2a2",
   "metadata": {},
   "source": [
    "So the l1-regularized model performs better than the default l2-regularized one. But how much is it due to the fact that I have also changed the solver from the default `lbfgs` to `saga`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "decd28e6-e253-44b4-a3be-f16254a93f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8524590163934426\n",
      "F1: 0.8732394366197183\n",
      "Precision: 0.8157894736842105\n",
      "Recall: 0.9393939393939394\n",
      "AUC: 0.8446969696969697\n"
     ]
    }
   ],
   "source": [
    "l2_saga_regression = LogisticRegression(max_iter=10000, penalty=\"l2\", solver=\"saga\")\n",
    "l2_saga_regression.fit(train_x, train_y)\n",
    "\n",
    "print_metrics(l2_saga_regression, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88009e-f925-41be-95c8-d1e852417be7",
   "metadata": {},
   "source": [
    "What about elasticnet penalty?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d330b333-2c3c-4b20-a972-6e52696d5b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8524590163934426\n",
      "F1: 0.8732394366197183\n",
      "Precision: 0.8157894736842105\n",
      "Recall: 0.9393939393939394\n",
      "AUC: 0.8446969696969697\n"
     ]
    }
   ],
   "source": [
    "elasticnet_regression = LogisticRegression(max_iter=10000, penalty=\"elasticnet\", solver=\"saga\", l1_ratio=0.5)\n",
    "elasticnet_regression.fit(train_x, train_y)\n",
    "\n",
    "print_metrics(elasticnet_regression, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a52f67-0df3-4e72-b67d-78013994cec1",
   "metadata": {},
   "source": [
    "So it seems that the regularization type has no effect on the result. What about stronger and weaker regularization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e14f023c-dedf-49de-b7f9-5729cdcf46b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stronger Regularization:\n",
      "Accuracy: 0.8524590163934426\n",
      "F1: 0.8732394366197183\n",
      "Precision: 0.8157894736842105\n",
      "Recall: 0.9393939393939394\n",
      "AUC: 0.8446969696969697\n"
     ]
    }
   ],
   "source": [
    "l2_stronger_regression = LogisticRegression(max_iter=10000, penalty=\"l2\", solver=\"saga\", C=0.1)\n",
    "l2_stronger_regression.fit(train_x, train_y)\n",
    "\n",
    "print(\"Stronger Regularization:\")\n",
    "print_metrics(l2_stronger_regression, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d02a5d47-352d-4d59-84e9-c479aa560966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weaker Regularization:\n",
      "Accuracy: 0.8524590163934426\n",
      "F1: 0.8732394366197183\n",
      "Precision: 0.8157894736842105\n",
      "Recall: 0.9393939393939394\n",
      "AUC: 0.8446969696969697\n"
     ]
    }
   ],
   "source": [
    "l2_weaker_regression = LogisticRegression(max_iter=10000, penalty=\"l2\", solver=\"saga\", C=100)\n",
    "l2_weaker_regression.fit(train_x, train_y)\n",
    "\n",
    "print(\"Weaker Regularization:\")\n",
    "print_metrics(l2_weaker_regression, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10a3b3f-9397-48aa-82b9-e398380e5561",
   "metadata": {},
   "source": [
    "None of these changes (with a fixed max_iter and solver) have had any effect on the scores? Why does that happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534d3a9d-eb33-4c33-9312-52fb2873db47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_exploration",
   "language": "python",
   "name": "ml_exploration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
